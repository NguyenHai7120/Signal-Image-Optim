{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Backward et FISTA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##    NGUYEN Minh Hai - LE Cam Thanh Ha - 4 GMM A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce TP, nous allons utiliser l'algorithme dit Forward Backward et sa version accélérée appelée FISTA pour résoudre différents problèmes d'optimisation associés à de l'inpainting et du débruitage. Nous travaillerons sur les deux images de référence du TP précédent mais à nouveau, vous pouvez utiliser d'autres images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as scp\n",
    "import pylab as pyl\n",
    "import pywt\n",
    "import pandas as pd\n",
    "import holoviews as hv\n",
    "import param\n",
    "import panel as pn\n",
    "from panel.pane import LaTeX\n",
    "hv.extension('bokeh')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local=0\n",
    "def chargeData(name):\n",
    "    if local:\n",
    "        if name=='Lenna':\n",
    "            res=np.array(Image.open(\"./Archive/img/Lenna.jpg\")).astype(float)\n",
    "        if name=='Canaletto':\n",
    "            res=np.array(Image.open(\"./Archive/img/Canaletto.jpeg\")).astype(float)\n",
    "        if name=='Minotaure':\n",
    "            res=np.array(Image.open(\"./Archive/img/MinotaureBruite.jpeg\")).astype(float)   \n",
    "        if name=='Cartoon':\n",
    "            res=np.array(Image.open(\"./Archive/img/Cartoon.jpg\")).astype(float) \n",
    "    else:\n",
    "        if name=='Lenna':\n",
    "            url='https://plmlab.math.cnrs.fr/dossal/optimisationpourlimage/raw/master/img/Lenna.jpg'        \n",
    "            response = requests.get(url)\n",
    "            res=np.array(Image.open(BytesIO(response.content))).astype(float)\n",
    "        if name=='Canaletto':\n",
    "            url='https://plmlab.math.cnrs.fr/dossal/optimisationpourlimage/raw/master/img/Canaletto.jpeg'\n",
    "            response = requests.get(url)\n",
    "            res=np.array(Image.open(BytesIO(response.content))).astype(float)\n",
    "        if name=='Minotaure':\n",
    "            url='https://plmlab.math.cnrs.fr/dossal/optimisationpourlimage/raw/master/img/MinotaureBruite.jpeg'\n",
    "            response = requests.get(url)\n",
    "            res=np.array(Image.open(BytesIO(response.content))).astype(float)\n",
    "        if name=='Cartoon':\n",
    "            url='https://plmlab.math.cnrs.fr/dossal/optimisationpourlimage/raw/master/img/Cartoon.jpg'        \n",
    "            response = requests.get(url)\n",
    "            res=np.array(Image.open(BytesIO(response.content))).astype(float)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenna = chargeData(\"Lenna\")\n",
    "cana = chargeData(\"Canaletto\")\n",
    "imagesRef= {\"Lenna\" : lenna,\"Canaletto\" : cana}\n",
    "options = dict(cmap='gray',xaxis=None,yaxis=None,width=400,height=400,toolbar=None)\n",
    "pn.Row(hv.Raster(imagesRef[\"Lenna\"]).opts(**options),hv.Raster(imagesRef[\"Canaletto\"]).opts(**options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSNR(I,Iref):\n",
    "    temp=I.ravel()\n",
    "    tempref=Iref.ravel()\n",
    "    NbP=I.size\n",
    "    EQM=np.sum((temp-tempref)**2)/NbP\n",
    "    b=np.max(np.abs(tempref))**2\n",
    "    return 10*np.log10(b/EQM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inpainting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour le problème d'inpainting on va supposer qu'on dispose d'observations $y=Mx^0+b$ qui sont dégradées par un opérateur de masquage $M$ et éventuellement par un bruit additif $b$. On va chercher à estimer $x^0$ en minimisant une fonctionnelle de la forme \n",
    "\\begin{equation}\\label{Eq1}\n",
    "\\frac{1}{2}\\Vert Mx-y\\Vert^2+\\lambda \\Vert Tx\\Vert_1\n",
    "\\end{equation}\n",
    "où $T$ est une transformée dans laquelle on sait que l'image $x^0$ est parcimonieuse (typiquement une bonne base d'ondelettes comme db2). Pour utiliser le FB, il faut calculer le gradient du terme d'attache aux données et l'opérateur proximal de $\\Vert Tx\\Vert_1$. Vous aurez de l'aide plus loin dans le notebook pour cette partie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si le bruit est nul, c'est-à-dire si $y=Mx^0$, où $M$ est un opérateur de masquage, il serait même plus intéressant de déterminer une solution du problème d'optimisation suivant :\n",
    "\\begin{equation}\\label{Eq2}\n",
    "\\underset{x}{\\min}\\Vert Tx\\Vert_1\\text{ sous la contrainte }y=Mx  \n",
    "\\end{equation}\n",
    "Ce problème d'optimisation ne peut être résolu directement par par l'algorithme Forward-Backward (FB) car on ne peut pas le formuler comme une minimsaition d'une somme de deux fonctions dont l'unde est différentiable à gradient Lipschitz. \n",
    "De plus, en pratique, il est souvent illusoire de penser que les données $y$ ne sont pas corrompues par un bruit, aussi petit soit il. \n",
    "\n",
    "On peut démontrer que les solutions de \\eqref{Eq1} convergent ver une solution de \\eqref{Eq2} quand $\\lambda$ tend vers 0. L'avantage de cette formulation \\eqref{Eq1} est qu'elle peut être résolu par FB. \n",
    "Résoudre \\eqref{Eq1} revient ainsi à la fois à inpainter et à régulariser. Plus $\\lambda$ est grand plus on régularise. Dans la pratique, en l'absence de bruit, on a intérêt à choisir une petite valeur de $\\lambda$ dans la formulation \\eqref{Eq1}. Le problème dun tel choix est que ça ralentit l'algorithme : i.e il faut un plus grand nombre d'itérations pour atteindre un résultat comparable si on prend le même point de départ. Quand on utilise ces méthodes, les choix de $\\lambda$, du nombre d'itérations et du point de départ de l'algorithme sont importants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Commentaire :\n",
    "\n",
    "<span style = \"color:blue\">\n",
    "    \n",
    "     On formalise notre problème de l'inpainting comme un problème d'optimisation, car en général on a un bruit additif $b$ et l'opérateur $M$ (qui est un projecteur orthogonale au point de vue Mathématique) n'est pas inversible. La norme $l_1$ nous aide à trouver une solution parcimonieuse. \n",
    "    \n",
    "</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M : projecteur orthogonale qui n'est pas inversible\n",
    "\n",
    "norm l1 -> parcimoniouse\n",
    "\n",
    "prox_g(x) = seuillage doux avec un seuil = gamma*lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rappels sur la descente de gradient explicite et sur Forward-Backward (FB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si $F=f+g$ est une fonction convexe composite, somme de deux fonctions convexes, $f$ différentiable à gradient \n",
    "$L$-Lipschitz et $g$ une fonction convexe dont on sait calculer l'opérateur proximal, l'algorithme Forward-Backward s'écrit \n",
    "$$x_{n+1}=prox_{hg}(x_n-h\\nabla f(x_n))=Tx_n\\quad \\text{ avec }T:=prox_{hg}\\circ (Id-h\\nabla f)$$\n",
    "\n",
    "On peut montrer que la suite de terme général $F(x_n)-F(x^*)$ est décroissante et de plus que \n",
    "$$F(x_n)-F(x^*)\\leqslant \\frac{2\\Vert x_0-x^*\\Vert^2}{hn}$$\n",
    "Cette vitesse en $\\frac{1}{n}$ est optimale au sens où il n'est pas possible de trouver des bornes qui décroissent en $\\frac{1}{n^{\\delta}}$ avec $\\delta>1$ pour toutes les fonctions convexes. Cela étant on peut montrer que si $h<\\frac{1}{L}$ on a en fait \n",
    "$$F(x_n)-F(x^*)=o\\left(\\frac{1}{n}\\right)$$\n",
    "et que cette vitesse est même géométrique si la fonction $f$ est fortement convexe, dans le cas différentiable. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remarques sur les algorithmes itératifs en général et FB en particulier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lorsqu'on utilise un algorithme itératif qui dépend d'un ou plusieurs paramètres, il faut être vigilent pour évaluer ses performances. Il est important de s'assurer d'une manière ou d'une autre des points suivants :\n",
    "\n",
    "1) Vérifier qu'on est proche de la convergence... c'est-à-dire qu'on a fait suffisamment d'itérations. Ce nombre peut varier en fonction des paramètres de l'agorithme et du point initial $x_0$ choisi pour construire la suite.\n",
    "\n",
    "Je vous invite pour cela à afficher la courbe de la valeur de la fonctionnelle et à prendre un peu de recul sur ce que vous observez. S'il reste des pixels noirs qui sont manifestement des résidus du masque ou si la fonctionnelle décroit encore fortement, c'est qu'il faut sans doute augmenter le nombre d'itérations. D'une manière générale, observer les artefacts (défauts) de l'image reconstruite peut donner des éléments de réponses.\n",
    "De plus, observer la courbe de la valeur de la fonctionnelle peut parfois indiquer qu'on aurait pu effectuer moins d'itérations pour un résulat comparable. \n",
    "\n",
    "2) Explorer les valeurs des paramètres. Il se peut que certaines valeurs de paramètres fournissent des résultats pertinents, d'autres non. Avant de trancher sur le caractère efficace d'une méthode, il faut avoir pris le temps de vérifier que le choix des paramètres est correct. Les paramètres peuvent être ceux de la fonctionnelle à minimiser, comme le $\\lambda$ de \\eqref{Eq1} mais aussi des paramètres internes à l'algorithme comme le pas de descente par exemple. Le fait de faire un plan d'expériences dans ce cas sur des données tests peut être un bon moyen de déterminer des paramètres pertinents. \n",
    "\n",
    "On peut noter que la valeur de la fonctionnelle ne fait pas tout, en effet si on veut comparer différentes valeur de $\\lambda$, c'est plutôt le PSNR de la reconstruction qui sera un critère pertinent. On ne peut pas se passer de réfléchir... \n",
    "\n",
    "3) Bien choisir la valeur initiale de la suite. Les algorithmes itératifs construisent de manière séquentielle des images qui s'approchent du minimiseur de la fonctionnelle. Le choix du point de départ de la suite peut être crucial.\n",
    "Si on ne dispose d'aucune information a priori, on peut partir d'une image constante à 0 ou d'une image raisonnable.\n",
    "Par exemple, de l'image masquée si on fait de l'inpainting, ou de l'image bruitée si on fait du débruitage.\n",
    "\n",
    "On peut souvent distinguer deux phases dans l'optimisation de la fonctionnelle, une première qui permet de passer de l'image initiale vers une image raisonnable, une approximation grossière du résultat, puis une seconde qui permet de passer de cette première approximation grossière à une image très proche du résultat final souhaité.\n",
    "Il est difficile d'esquiver la seconde phase mais on peut réduire drastiquement la première en proposant une image initiale déjà très raisonnable. On peut par exemple lancer un algorithme classique rapide, mais pas très précis pour donner une image initiale meilleure qu'une initialisation aléatoire ou naïve. \n",
    "Dans le cas du débruitage, on peut par exemple filtrer l'image originale ou la seuiller en ondelettes. Dans le cas de l'inpainting on peut appliquer localement un filtre médian. C'est-à-dire on découpe l'image en blocs de taille fixe (8 par 8 par exemple) et sur chaque bloc on estime la valeur médianne d'intensité lumineuse parmi les valeurs non masquées et on remplace, sur chaque bloc, les valeurs inconnues par cette valeur. C'est primitif mais rapide et ça permet d'avoir une première estimation raisonnable.\n",
    "\n",
    "D'une manière générale, si vous voulez comparer plusieurs méthodes, avec des paramètres ou des bases d'ondelettes différentes, il est pertinent de calculer le PSNR des images reconstruites. \n",
    "C'est une manière d'obtenir un critère un minimum objectif."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mise en place de FB pour l'inpainting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On pourra commencer dans un premier temps par des observations non bruitées et effectuer seulement un masquage. Pour créer un masque 2D, on peut utiliser les lignes de commandes suivantes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed = 1)\n",
    "n1, n2 = np.shape(lenna)\n",
    "r = np.random.rand(n1,n2)\n",
    "M = (r < 0.5)\n",
    "M = M * 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "On peut bien entendu faire varier la proportion de l'image qu'on masque.\n",
    "\n",
    "On masque l'image de la manière suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = M * lenna\n",
    "pn.Row(hv.Image(lenna).opts(cmap = 'gray', width = 400, height = 400), hv.Image(temp).opts(cmap='gray', width=400, height=400))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style = \"color:blue\">\n",
    "    \n",
    "     En effectuant un masquage, il y a des pixels devenant noirs et l'image est bien masquée\n",
    "    \n",
    "</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initilisation par un filtre médian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proposer et tester un algorithme de Filtre médian qui réalise un inpainting primaire en rempalçant les pixels manquants par la mediane des coefficients observés sur des carrés de taille vois*vois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FiltreMedian(im, masque, vois):\n",
    "    imrec = np.copy(im)\n",
    "    n1, n2 = np.shape(im)\n",
    "    K1 = int(np.floor(n1/vois))\n",
    "    K2 = int(np.floor(n2/vois))\n",
    "    for k1 in np.arange(K1):   # Loop over dim = 0\n",
    "        for k2 in np.arange(K2):  # Loop over dim = 1\n",
    "            bloc = imrec[k1*vois:(k1+1)*vois, k2*vois:(k2+1)*vois]\n",
    "            median = np.median(bloc[bloc != 0])\n",
    "            imrec[k1*vois:(k1+1)*vois, k2*vois:(k2+1)*vois ] += (masque[k1*vois:(k1+1)*vois, k2*vois:(k2+1)*vois ] == 0)*median\n",
    "            \n",
    "    return(imrec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation le résultat du filtre médian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imrec2 = FiltreMedian(temp, M, 8)\n",
    "pn.Row(hv.Raster(temp).opts(title = 'Image masquée', cmap='gray',xaxis=None,yaxis=None,width=350,height=350), \n",
    "          hv.Raster(imrec2).opts(title = 'Image filtre médian', cmap='gray',xaxis=None,yaxis=None,width=350,height=350))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1, n2 = np.shape(cana)\n",
    "r = np.random.rand(n1,n2)\n",
    "M_cana = (r < 0.5)\n",
    "M_cana = M_cana * 1.0\n",
    "cana_masque = M_cana * cana\n",
    "imrec_cana = FiltreMedian(cana_masque, M_cana, 8)\n",
    "pn.Row(hv.Raster(cana_masque).opts(title = 'Image masquée', cmap='gray',xaxis=None,yaxis=None,width=350,height=350), \n",
    "          hv.Raster(imrec_cana).opts(title = 'Image filtre médian', cmap='gray',xaxis=None,yaxis=None,width=350,height=350))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Commentaire\n",
    "<span style = \"color:blue\">\n",
    "    \n",
    "     Le filtre médian est simple à implémenter et rapide à exécuter. Pourtant, il nous donne une très bonne initialisation pour notre algorithme d'optimisation itérative. \n",
    "Cette étape est très important en optimisation, même on a un problème d'optimisation convexe et l'algorithme Forward-Backward assure une convergence globale, un point \n",
    "de départ qui n'est pas très loin de la solution optimale nous aide à réduire le nombre d'itérations donc le temps d'éxecution. \n",
    "    \n",
    "</span> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retour sur l'algorithme FB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proposer une fonction qui calcule le gradient de la fonction $f(x)=\\frac{1}{2}\\Vert Mx-y\\Vert^2$ :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style = \"color:blue\">\n",
    "\n",
    "Car M est un projecteur orthogonal donc $M^T = M$ et $M \\circ M = M$\n",
    "    \n",
    "On en obtient le gradient : $$ \\Delta f(x) = M^T(Mx-y) = M^T M x -M^T y = M(x-y)$$\n",
    "    \n",
    "    \n",
    "</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GradientInpainting(x, y, M):\n",
    "    g = M*(x - y)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour quelle valeur $L$ ce gradient est-il $L$-Lipschitz ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style = \"color:blue\">\n",
    " On a:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\lVert \\nabla f(x)-\\nabla f(y) \\rVert = \\lVert M(x-y) \\rVert \\leq \\lVert M \\rVert \\times \\lVert x - y \\rVert\n",
    "\\end{equation}\n",
    "\n",
    "Donc la fonction $f$ est à gradient $L$-lipschitz avec $L$ = $ \\lVert M \\rVert$.\n",
    "\n",
    "De plus, comme $M$ est un projecteur orthogonale, il est de norme $1$, donc $f$ est à gradient $1$-lipschitz\n",
    "</span> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les fonctions suivantes permettent d'évaluer l'opérateur proximal de la fonction \n",
    "$g(x)=\\lambda \\Vert Tx\\Vert_1$ où $T$ est une transformée orthogonale en ondelettes ou une transformée en ondelettes à trou, c'est-à-dire invariante par translation. Vous noterez qu'une transformée en Ondelettes de Daubechies db2 à été choisie ici par défaut mais que ce ci peut bien entendu être changé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SeuillageDouxOndelettes(I, wave, Seuil):\n",
    "    '''\n",
    "    i.e l'opérateur proximal de lambda * norme_l1(Tx) , avec lambda = Seuil\n",
    "    '''\n",
    "    L = pywt.dwt_max_level(len(I), pywt.Wavelet(wave).dec_len)\n",
    "    wavelet_coeffs = pywt.wavedecn(I, wave, mode = 'per', level = L)\n",
    "    arr, coeff_slices, coeff_shapes = pywt.ravel_coeffs(wavelet_coeffs)\n",
    "    temp = pywt.threshold(arr, Seuil, mode = 'soft')\n",
    "    test = pywt.unravel_coeffs(temp, coeff_slices, coeff_shapes, output_format = 'wavedecn')\n",
    "    Irec = pywt.waverecn(test, wave, mode = 'per')\n",
    "    return Irec\n",
    "\n",
    "def Normel1Ondelettes(I, wave):\n",
    "    L = pywt.dwt_max_level(len(I),pywt.Wavelet(wave).dec_len)\n",
    "    wavelet_coeffs = pywt.wavedecn(I, wave, mode = 'per', level = L)\n",
    "    arr, coeff_slices, coeff_shapes = pywt.ravel_coeffs(wavelet_coeffs)\n",
    "    norml1 = sum(np.abs(arr))\n",
    "    return norml1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave = 'haar'\n",
    "imrec = SeuillageDouxOndelettes(lenna, wave, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proposer et tester un code d'inpaiting utilisant Forward-Backward minimisant la fonctionnelle (1) et la tester.\n",
    "\n",
    "On pensera à cliper le résultat entre 0 et 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Loss_F(z, y, M, lamb, wave):\n",
    "    return 0.5 * np.sum((np.abs(M*z - y)**2)) + lamb * Normel1Ondelettes(z, wave)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ForwardBackwardInpaintingv2(x, y, M, step, lam, Niter, wave):\n",
    "    z = FiltreMedian(y, M, 8)\n",
    "    PSNR_list = [PSNR(z, x)]\n",
    "    Losses = [Loss_F(z, y, M, lam, wave)]\n",
    "    \n",
    "    for i in range(Niter):\n",
    "        grad = GradientInpainting(z, y, M)   # gradient de f(s)\n",
    "        z = SeuillageDouxOndelettes(I = z - step*grad, wave = wave, Seuil = step*lam)        # Calculer l'operateur proximal\n",
    "        PSNR_list.append(PSNR(z, x))\n",
    "        Losses.append(Loss_F(z, y, M, lam, wave))\n",
    "    \n",
    "    PSNR_list = np.array(PSNR_list)\n",
    "    Losses = np.array(Losses)\n",
    "    \n",
    "    return np.clip(z, 0, 255), PSNR_list, Losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appliquer à l'image masquée de Lenna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = M * lenna\n",
    "step = 0.95\n",
    "lam = 5\n",
    "Niter = 100\n",
    "wave = 'haar'\n",
    "Ta = 350\n",
    "imrec, psnr, losses = ForwardBackwardInpaintingv2(lenna, y, M, step, lam, Niter, wave)\n",
    "pn.GridBox(hv.Image(lenna).opts(title = \"Image original\", cmap = 'gray', width = Ta, height = Ta),\n",
    "       hv.Image(y).opts(title = \"Image masquée\", cmap = 'gray', width = Ta, height = Ta),\n",
    "       hv.Image(FiltreMedian(y, M, 8)).opts(title = \"Filtre médian\", cmap = 'gray', width = Ta, height = Ta)\n",
    "       ,hv.Image(imrec).opts(title = \"Image reconstruite par FB\", cmap='gray', width = Ta, height = Ta), ncols = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.Curve(psnr).opts(title = \"Evolution de PSNR\", width = 600, height = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.Curve(losses).opts(title = \"Evolution de la fontion coût\", width = 600, height = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Commentaire\n",
    "<span style = \"color:blue\">\n",
    "    \n",
    "     En minimisant la fonction coût et utilisant une transformée en endelettes de Haar, on a obtenu un résultat assez proche de l'image initiale. Grâce à l'initialisation par filtre médian, l'algorithme converge rapidement (avec 100 itérations on obtient une image assez claire). Par contre, on peut constater que la solution obtenue contient des effets \"carrés\", c'est normal parce qu'on a utilise les ondelettes de Haar dont les fonctions d'échelles sont constantes par morceaux. De plus, la fonction coût et le PSNR ne varie pas beaucoup a partir de 80e itération. \n",
    "</span> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelist = ['haar','db2','db3','db4','coif1','coif2','coif3']\n",
    "imagesRef= {\"Lenna\" : lenna,\"Canaletto\" : cana}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proposer un dashboard permettant une exploration numérique de la fonction précédente. On pourra ainsi observer que les petites valeurs de $\\lambda$ donnent de meilleurs résulats. En théorie, si les données observées ne sont pas bruitées, il faudrait prendre une valeur de $\\lambda$ aussi petite que possible. Vous pouvez le remarquer si vous affichez le PSNR de l'image reconstruite et que vous faites un nombre suffisant d'itérations.\n",
    "\n",
    "Le problème d'un tel choix est que cela ralentit considérablement l'algorithme. Si les données sont bruitées, la valeur optimale de $\\lambda$ est proportionnelle à lécart type du bruit.  \n",
    "\n",
    "Ainsi, vous aurez intérêt à choisir une valeur faible de $\\lambda$ mais pas trop petite pour assurer que votre algorithme est proche de la convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FBInpaint(param.Parameterized):\n",
    "    wave = param.ObjectSelector(default = \"haar\", objects = wavelist)\n",
    "    image = param.ObjectSelector(default = \"Canaletto\", objects = imagesRef.keys())\n",
    "    Niter = param.Integer(10, bounds = (0,300))\n",
    "    lam = param.Number(10, bounds = (1,30))\n",
    "    step = param.Number(0.9, bounds = (0.5,4))\n",
    "    masquage = param.Number(0.5, bounds = (0.1,1))\n",
    "    def view(self):\n",
    "        I = imagesRef[self.image]\n",
    "        n1, n2 = np.shape(I)\n",
    "        r = np.random.rand(n1, n2)\n",
    "        M = (r < self.masquage)\n",
    "        M = M * 1.0\n",
    "        im_mas = M * I\n",
    "        im_rec, psnr, losses = ForwardBackwardInpaintingv2(x = I, y = im_mas, M = M, step = self.step, lam = self.lam, Niter = self.Niter, wave = self.wave)\n",
    "        \n",
    "        return pn.GridBox(hv.Image(I).opts(title = \"Image original\", cmap = 'gray', width = 350, height = 350),\n",
    "                     hv.Image(im_mas).opts(title = \"Image masquée\", cmap = 'gray', width = 350, height = 350),\n",
    "                     hv.Image(im_rec).opts(title = \"Image reconstruite\", cmap='gray', width = 350, height = 350), ncols = 2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fbinpaint = FBInpaint()\n",
    "pn.Row(fbinpaint.param, fbinpaint.view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style = 'color:blue'>\n",
    "\n",
    "#### Commentaire\n",
    "\n",
    "- Globalement, cette modélisation du problème de l'inpaiting sous forme d'un problème d'optimisation convexe utilisant les bases d'ondelettes est très efficace, car on a des bonnes propriétés théoriques ainsi que l'algorithme Forward-Backward donne les bons résultats\n",
    "- Bases ondelettes: la base de Haar a une présence des effets carrés car les fonctions sont constantes par morceaux.\n",
    "- L'effet du bord: on constate des pertes d'informations sur les bords de l'image, car on a calculé la transformée en ondelette avec le mode 'périodique'\n",
    "- Le paramètre `lambda`: mesure l'effet de la transformée en ondelettes, plus `lambda` est grand, plus on force la transformée en ondelette $Tx$ être parcimonieuse, donc plus de propriétés des ondelettes influencent le résultat. On peut voir très  clair dans le cas de Haar, si `lambda` est grand, l'effet de carré est plus nette.\n",
    "- Le nombre d'itération: grâce à l'initialisation par le filtre médian, on a réduit significativement le nombre d'itérations.\n",
    "- Le pas de descent: théoriquement, l'algorithme Forward-Backward est un algorithme de descent si le pas $s < \\frac{2}{L} = 2$. Donc on peut accélérer la convergence en mettant le pas $ s = 1.99$. En pratique, on peut même mettre le pas $s$ plus grand que $2$ pour accélérer la convergence, mais il faut faire attention car si $s > 2$, on n'est pas assuré la convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accélération de Nesterov, FISTA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yuri Nesterov a proposé dans les années 1980 plusieurs méthodes permettant l'accélération de la descente de gradient explicite. Nous allons nous intéresser à une en particulier, celle qui est détaillée dans le polycopié de cours. Si vous faites des recherches bibliographiques, soyez conscients que sous le terme \"Accélération de Nesterov\" peuvent se cacher différentes méthodes, par interpolation ou extrapolation, spécifiques aux fonctions fortement convexes ou pas, s'appliquant à une descente de gradient simple ou à des fonctions composites. De plus nous n'utiliserons pas les paramètres historiques proposés par Nesterov, mais ceux qu'Antonin Chambolle et moi même avons proposé en 2014 pour en améliorer la vitesse et la convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'accélération de la descente de gradient proposée Yurii Nesterov en 1984 et adapatée à FB sous le nom de FISTA par Beck et Teboulle en 2009 est d'une mise en oeuvre très simple.\n",
    "\n",
    "Il suffit d'effectuer la descente de gradient en un point décalé de $x_n$ avec un pas $h<\\frac{1}{L}$ (attention cette borne est plus contraignante que pour la descente de gradient classique) :\n",
    "$$x_{n+1}=T(x_n+\\alpha_n(x_n-x_{n-1}))$$ \n",
    "où la suite $\\alpha_n$ est bien choisie et $T$ st soit l'opérateur de descente de gradient explicite, soit l'opérateur associé au FB. On parle de méthode inertielle car cette méthode utilise un terme dit de \"mémoire\" ou inertiel qui exploite la dernière direction de descente.\n",
    "\n",
    "Donnons quelques éléments clés importants :\n",
    "\n",
    "1) Le choix original de Nesterov pour la suite $\\alpha_n$ ets le suivant :\n",
    "\\begin{equation}\n",
    "\\alpha_n=\\frac{t_n-1}{t_{n+1}}\\text{ avec }t_1=1\\text{ et }t_{n+1}=\\frac{1+\\sqrt{1+t_n^2}}{2}\n",
    "\\end{equation}\n",
    "2) Pour ce choix on a \n",
    "$$F(x_n)-F(x^*)\\leqslant \\frac{2\\Vert x_0-x^*\\Vert^2}{hn^2}$$\n",
    "3) On peut prendre plus simplement $\\alpha_n=\\frac{n-1}{n+a-1}$ avec $a>3$ (c'est ce que vous programmerez) dans ce cas, on a $$F(x_n)-F(x^*)\\leqslant \\frac{(a-1)^2\\Vert x_0-x^*\\Vert^2}{2h(n+a)^2}$$ et en plus $F(x_n)-F(x^*)=o\\left(\\frac{1}{n^2}\\right)$ et on a convergence de la suite $(x_n)_{n\\geqslant 1}$. On peut noter que dans ce cas, la première étape est une simple sans inertie ($\\alpha_1=0$) et donc $x_1=T(x_0)$. L'inertie apparait pour le calcul de $x_2$. Le choix originel de Nesterov est très proche du choix $a=3$. \n",
    "\n",
    "4) Dans le cas d'un fonction composite, on parle de l'algotithme FISTA (Fast Iterative Soft Shrinckage Algorithm) car si $g$ est une norme $\\ell_1$, l'opérateur proximal se réduit à un seuillage doux. Mais FISTA est le nom générique proposé par Beck et Teboulle en 2009, ce peut être trompeur.\n",
    "\n",
    "5) La suite de terme général $F(x_n)-F(x^*)$ n'est pas nécessairemment décroissante comme dans le cas de FB ou de la descente de gradient. Les bornes données précédemment sont des bornes mais ne reflètent pas la décroissance réelle. Dans la pratique vous verrez que FISTA est quand même plus rapide que FB.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proposer un algorithme d'inpainting consistant à minimiser la fonctionnelle (1) en utilisant FISTA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FISTAInpainting(x, y, M, step, lam, Niter, wave, alpha):\n",
    "    z = FiltreMedian(y, M, 8)\n",
    "    f = [PSNR(z, x)]\n",
    "    \n",
    "    # First iteration alpha = 0\n",
    "    grad = GradientInpainting(z, y, M)\n",
    "    z_old = z\n",
    "    z = SeuillageDouxOndelettes(z - step*grad, wave, Seuil = step*lam)\n",
    "    f.append(PSNR(z, x))\n",
    "    \n",
    "    for k in range(1, Niter):\n",
    "        temp = z + (k/(k + alpha))*(z - z_old)\n",
    "        grad = GradientInpainting(temp, y, M)\n",
    "        z_old = z\n",
    "        z = SeuillageDouxOndelettes(temp - step*grad, wave, Seuil = step*lam)\n",
    "        f.append(PSNR(z, x))\n",
    "        \n",
    "    f = np.array(f)\n",
    "    \n",
    "    return np.clip(z, 0, 255), f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imrec, f = FISTAInpainting(lenna, y, M, step, lam, 75, wave, 4)\n",
    "pn.Row(hv.Image(lenna).opts(title = 'Image original', cmap = 'gray', width = Ta, height = Ta),\n",
    "       hv.Image(y).opts(title = 'Image masquée', cmap = 'gray', width = Ta, height = Ta),\n",
    "       hv.Image(imrec).opts(title = 'Image reconstruite par FISTA', cmap = 'gray', width = Ta, height = Ta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.Curve(f).opts(title = \"Evolution de PSNR\", xlabel = 'Itération', ylabel = 'PSNR', width = 600, height = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FISTAInpaint(param.Parameterized):\n",
    "    wave = param.ObjectSelector(default=\"haar\",objects=wavelist)\n",
    "    image = param.ObjectSelector(default=\"Canaletto\",objects=imagesRef.keys())\n",
    "    Niter = param.Integer(10,bounds=(0,300))\n",
    "    lam = param.Number(10,bounds=(1,30))\n",
    "    step = param.Number(0.9,bounds=(0.5,4))\n",
    "    masquage = param.Number(0.5,bounds=(0.1,1))\n",
    "    alpha = param.Number(3,bounds=(1,10))\n",
    "    def view(self):\n",
    "        I = imagesRef[self.image]\n",
    "        n1, n2 = np.shape(I)\n",
    "        r = np.random.rand(n1, n2)\n",
    "        M = (r < self.masquage)\n",
    "        M = M * 1.0\n",
    "        im_mas = M * I\n",
    "        im_rec, psnr = FISTAInpainting(x = I, y = im_mas, M = M, step = self.step, lam = self.lam, Niter = self.Niter, wave = self.wave, alpha = self.alpha)\n",
    "        \n",
    "        return pn.GridBox(hv.Image(I).opts(title = \"Image original\", cmap = 'gray', width = 350, height = 350),\n",
    "                     hv.Image(im_mas).opts(title = \"Image masquée\", cmap = 'gray', width = 350, height = 350),\n",
    "                     hv.Image(im_rec).opts(title = \"Image reconstruite par FISTA\", cmap='gray', width = 350, height = 350), ncols = 2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fistainpaint= FISTAInpaint()\n",
    "pn.Row(fistainpaint.param, fistainpaint.view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style = 'color:blue'>\n",
    "\n",
    "#### Commentaire\n",
    "\n",
    "- Cette méthode FISTA converge plus rapide que Forward-Backward, elle a besoin moind d'itérations pour converger \n",
    "- Les mêmes effets carrés avec les ondelettes de Haar\n",
    "- FISTA est moins sensible avec le paramètre `lambda`, elle peut converger vers une bonne solutions avec différentes valeurs de `lambda`\n",
    "- Il y a toujours les effets du bord de l'image (à cause de la transformée périodique)\n",
    "- Attention: il ne faut pas mettre un pas trop grand et beaucoup d'itération car un pas trop grand ne assure pas la convergence et peut éventuellement donner le mauvais résultat. Mais un pas de descent raisonnable peut accélérer encore la convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pour aller plus loin (facultatif et à titre d'information) - Inpainting en utilisant les bases d'ondelettes translattées (décalage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme pour le débruitage, on peut utiliser des bases d'ondelettes translatées pour améliorer la qualité de l'inpainting. Dans ce cas, il ne faut évidemment pas recalculer l'inpainting depuis le début pour chaque version translatée, mais utiliser comme initialisation les versions inpaintées précédentes. \n",
    "Cette variante permet également de lisser les défauts et supprime des effets liés à la forme de l'ondelettes et donc les effets de blocs si on utilise les ondelettes de Haar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Principle\n",
    "Dans cette partie nous allons améliorer les résultats obtenus précédamment en combinant plusieurs solutions décalées dans les bases d'ondelettes.\n",
    "L'idée de cette méthode est:\n",
    "- Decaler l'image i pixels horizontalement et j pixel verticalement avec $(i,j)\\in$ {1,2,3,4}$^2$\n",
    "- Pour chaque version decalée, effectuer FISA et decaler dans le sens inverse resulat obtenu.\n",
    "- Calculer la moyenne. On obtient le résultat final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On ecrit d'abord une fonction FISTA qui permet de résoudre le problème avec un point de départ précis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FISTAInpaintingInit(x, y, M, step, lam, Niter, wave, alpha, z_init):\n",
    "    z = z_init\n",
    "    \n",
    "    # First iteration alpha = 0\n",
    "    grad = GradientInpainting(z, y, M)\n",
    "    z_old = z\n",
    "    z = SeuillageDouxOndelettes(z - step*grad, wave, Seuil = step*lam)\n",
    "    \n",
    "    for k in range(1, Niter):\n",
    "        temp = z + (k/(k + alpha))*(z - z_old)\n",
    "        grad = GradientInpainting(temp, y, M)\n",
    "        z_old = z\n",
    "        z = SeuillageDouxOndelettes(temp - step*grad, wave, Seuil = step*lam)\n",
    "\n",
    "    return np.clip(z, 0, 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FISTA avec translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FISTAInpaintingTranslation(x, y, M, step, lam, Niter, wave, alpha, NbT):\n",
    "    z, _ = FISTAInpainting(x, y, M, step, lam, Niter, wave, alpha)\n",
    "    sum = np.copy(z)\n",
    "    \n",
    "    for k in range(NbT):\n",
    "        z_h = np.roll(z, k, axis = 0)\n",
    "        x_h = FISTAInpaintingInit(x, y, M, step, lam, Niter, wave, alpha, z_init = z_h)\n",
    "        z_h = np.roll(x_h, -k, axis = 0)\n",
    "        \n",
    "        z_h_2 = np.roll(z, -k, axis = 0)\n",
    "        x_h_2 = FISTAInpaintingInit(x, y, M, step, lam, Niter, wave, alpha, z_init = z_h_2)\n",
    "        z_h_2 = np.roll(x_h_2, k, axis = 0)\n",
    "        \n",
    "        z_v = np.roll(z, k, axis = 0)\n",
    "        x_v = FISTAInpaintingInit(x, y, M, step, lam, Niter, wave, alpha, z_init = z_v)\n",
    "        z_v = np.roll(x_v, -k, axis = 0)\n",
    "        \n",
    "        z_v_2 = np.roll(z, -k, axis = 0)\n",
    "        x_v_2 = FISTAInpaintingInit(x, y, M, step, lam, Niter, wave, alpha, z_init = z_v_2)\n",
    "        z_v_2 = np.roll(x_v_2, k, axis = 0)\n",
    "        \n",
    "        sum_k = z_h + z_h_2 + z_v + z_v_2\n",
    "#         sum_k = x_h + x_h_2 + x_v + x_v_2\n",
    "        sum = sum + sum_k\n",
    "        z = sum_k/4\n",
    "        \n",
    "    return sum / (NbT*4 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = M * lenna\n",
    "step = 0.95\n",
    "lam = 5\n",
    "Niter = 100\n",
    "wave = 'haar'\n",
    "Ta = 350\n",
    "imrec, _ = FISTAInpainting(lenna, y, M, step, lam, 150, wave, 3)\n",
    "imrec_trans = FISTAInpaintingTranslation(lenna, y, M, step, lam, 150, wave, 3, NbT = 3)\n",
    "\n",
    "print('PSNR de FISTA : ', PSNR(imrec, lenna))\n",
    "print('PSNR de FISTA avec translation : ', PSNR(imrec_trans, lenna))\n",
    "\n",
    "pn.GridBox(hv.Image(lenna).opts(title = \"Image original\", cmap = 'gray', width = Ta, height = Ta),\n",
    "       hv.Image(y).opts(title = \"Image masquée\", cmap = 'gray', width = Ta, height = Ta),\n",
    "       hv.Image(imrec).opts(title = \"Inpaiting par FISTA\", cmap = 'gray', width = Ta, height = Ta),\n",
    "       hv.Image(imrec_trans).opts(title = \"Inpaiting par FISTA et translations\", cmap = 'gray', width = Ta, height = Ta), ncols = 2 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style = 'color:blue'>\n",
    "\n",
    "### Commentaires:\n",
    "    \n",
    "En utilisant les translations, on a gagné un gain en terme de PSNR et le résultat est plus 'lisse', il y a moins de l'effet carré"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Débruitage par minimisation de la variation totale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si l'image qu'on souhaite débruiter une image dont on sait qu'elle a une faible variation totale (norme $\\ell_1$ du gradient), on peut estimer l'image en minimisant une fonctionnelle . Attention, on parle ici du gradient de l'image, pas d'une fonctionnelle qui associe une image à un réel. \n",
    "Le gradient d'une image est un champ de vecteur avec deux composantes, l'une verticale, l'autre horizontal qui se calcule de manière classique par différence finie. J'ai fait le choix dans les codes proposés d'une discrétisation du gradient et de la discrétisation de l'opérateur adjoint associé. En particulier, cette version n'est pas périodisée. Si vous voulez utiliser une autre implémentation du gradient discret, il est probable qu'il faille recoder l'opérateur \n",
    "adjoint.\n",
    "\n",
    "Si on note $y=x^0+b$ les observations où $x^0$ est l'image à estimer et $b$ un bruit additif, cette fonctionnelle sera de la forme \n",
    "\\begin{equation}\\label{Primal}\\tag{Primal}\n",
    "\\frac{1}{2}\\Vert x-y\\Vert^2+\\lambda \\Vert \\nabla x\\Vert_1\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimiser une telle fonctionnelle revient à caluler l'opérateur proximal de la fonction \n",
    "$g(x)=\\lambda \\Vert \\nabla x\\Vert_1$, or il n'existe pas de formule pour un tel opérateur. Ce qui implique aussi que réaliser un Forward Backward avec le terme quadratique comme terme différentiable ne peut pas fonctionner, il nécessite la connaissance de cet opérateur proximal.\n",
    "\n",
    "Il existe cependant un moyen d'utiliser l'algorithme FB pour résoudre ce problème : on procède par dualisation.\n",
    "Il n'est pas possible de détailler cette approche ici, je vous renvoie sur le Poly. La dualisation qui utilise la conjugué de Fenchel Rockafellar permet de montrer qu'on peut associer au problème précédent, le problème doptimisation suivant\n",
    "\\begin{equation}\\label{Dual}\\tag{Dual}\n",
    "\\min_{p}\\frac{1}{2}\\Vert div(p)+y\\Vert^2+\\iota_{\\mathcal{B}_{\\infty,\\lambda}}(p)\n",
    "\\end{equation}\n",
    "où $p$ est un champ de gradient et \n",
    "où $\\iota_{\\mathcal{B}_{\\infty,\\lambda}}$ est la boule $\\ell_{\\infty}$ de rayon $\\lambda$ et où $div$ est l'opérateur \n",
    "de divergence. La présence de la divergence est ici due au fait que $-div$ est l'opérateur adjoint du gradient $\\nabla$. La norme $\\infty$ est ici présente car c'est la norme duale de la norme $/ell_1$.\n",
    "\n",
    "Si $p^*$ est la solution du problème précédent alors $x^*=y+div(p^*)$ est la solution du problème initial.\n",
    "\n",
    "L'avantage de ce second problème est qu'il peut être résolu par l'algorithme FB dans la mesure où le terme non différentiable est une indicatrice d'un ensemble sur lequel on sait projeter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les fonctions suivantes permettent de calculer le gradient et la divergence.\n",
    "Tel que tout est codé ici, il s'agit d'une divergence négative, c'est à dire l'opposé de la divergence. A vous de voir si vous voulez tout remodifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GradientHor(x):\n",
    "    y = x - np.roll(x, 1, axis=1)\n",
    "    y[:,0] = 0\n",
    "    return y\n",
    "\n",
    "def GradientVer(x):\n",
    "    y = x - np.roll(x, 1 , axis=0)\n",
    "    y[0,:] = 0\n",
    "    return y\n",
    "\n",
    "def DivHor(x):\n",
    "    N = x.shape[1]\n",
    "    y = x - np.roll(x, -1, axis=1)\n",
    "    y[:, 0] = -x[:,1]\n",
    "    y[:, N-1] = x[:, N-1]\n",
    "    return y\n",
    "\n",
    "def DivVer(x):\n",
    "    N = x.shape[0]\n",
    "    y = x - np.roll(x, -1, axis=0)\n",
    "    y[0,:] = -x[1, :]\n",
    "    y[N-1,:] = x[N-1,:]\n",
    "    return y\n",
    "\n",
    "def Gradient(x):\n",
    "    y = []\n",
    "    y.append(GradientHor(x))\n",
    "    y.append(GradientVer(x))\n",
    "    return np.array(y)\n",
    "\n",
    "def Div(y):\n",
    "    # -div\n",
    "    x = DivHor(y[0]) + DivVer(y[1])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProjGradBouleInf(g, lamb):\n",
    "    # L'opérateur proximal\n",
    "    gh = g[0]\n",
    "    gv = g[1]\n",
    "    temp = np.copy(g)\n",
    "    p0 = gh - (gh - lamb)*(gh > lamb) - (gh + lamb)*(gh < -lamb)\n",
    "    p1 = gv - (gv - lamb)*(gv > lamb) - (gv + lamb)*(gv < -lamb)\n",
    "    temp[0] = p0\n",
    "    temp[1] = p1\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction Python qui résout le problème dual par Forward Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FBDenoisingTV(y, lamb, step, Niter):\n",
    "    \n",
    "    p = np.array([np.zeros(y.shape), np.zeros(y.shape)])\n",
    "    \n",
    "    for k in range(Niter):\n",
    "        grad = Gradient(- Div(p)) \n",
    "        # grad = np.dot(grad, - Div(p) + y)\n",
    "        grad[0] = np.dot(grad[0], - Div(p) + y)\n",
    "        grad[1] = np.dot(grad[1], - Div(p) + y)\n",
    "        \n",
    "        p = ProjGradBouleInf(p - step * grad, lamb)\n",
    "    \n",
    "    x  = y + Div(p)\n",
    "    return np.clip(x, 0, 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tester ce code sur un exemple d'image bruitée par un bruit gaussien. L'image résultante subit un effet Cartoon. Pourquoi ? Faite varier les paramètres pour voir les effets des différents paramètres de l'algorithme.  \n",
    "Le pas doit être maintenu en dessous de $1/8$ pour vérifier les conditions de Lipschitz du gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testons Forward-Backward pour minimiser la variation totale avec Lenna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1, n2 = np.shape(lenna)\n",
    "Sigma = 30\n",
    "Noise = np.random.rand(n1, n2)\n",
    "lenna_noised = lenna + Sigma * Noise\n",
    "\n",
    "lenna_denoised = FBDenoisingTV(lenna_noised, lamb = 5, step = 0.1, Niter = 1000)\n",
    "\n",
    "print(PSNR(lenna_denoised, lenna))\n",
    "\n",
    "pn.Row(hv.Image(lenna).opts(title = 'Image originale', cmap='gray',width = 350, height = 350),\\\n",
    "       hv.Image(np.clip(lenna_noised, 0, 255)).opts(title = 'Image bruitée',cmap = 'gray',width = 350, height = 350)\\\n",
    "       ,hv.Image(lenna_denoised).opts(title = 'Image débruitée par Variation Totale',cmap = 'gray', width = 350, height = 350))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style = 'color:blue'>\n",
    "\n",
    "### Commentaires:\n",
    "    \n",
    "On a obtenu un résultat assez clair sans perte d'informations et on peut éviter les effets de bords qu'on a vu dans le cas d'ondelettes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer le dashboard associé et tester l'algorithme sur différentes images et faites varier les paramètres.\n",
    "Le dashboard doit renvoyer 3 images et 2 PSNR. Vous devrier observer un effet \"cartoon\" surtout pour de grandes valeurs du paramètre $\\lambda$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenoisingTVFB(param.Parameterized):\n",
    "    Niter = param.Integer(100,bounds=(100,1000))\n",
    "    image = param.ObjectSelector(default=\"Lenna\", objects=imagesRef.keys())\n",
    "    lamb = param.Number(9,bounds=(0,50))\n",
    "    step = param.Number(0.1,bounds=(0.1,2))\n",
    "    Sigma = param.Number(30,bounds=(1,100))\n",
    "    \n",
    "    def view(self):\n",
    "        I = imagesRef[self.image]\n",
    "        n1, n2 = np.shape(I)\n",
    "        Noise = np.random.rand(n1, n2)\n",
    "        IB = I + self.Sigma * Noise\n",
    "        IDb = FBDenoisingTV(IB, self.lamb, self.step, self.Niter)\n",
    "        print('PSNR image bruitée: ', PSNR(IB, I))\n",
    "        print('PSNR image débruitée: ', PSNR(IDb, I))\n",
    "        \n",
    "        return pn.Row(hv.Image(np.clip(IB, 0, 255)).opts(title = 'Image bruitée',cmap = 'gray',width = 350, height = 350)\\\n",
    "                   ,hv.Image(IDb).opts(title = 'Image débruitée par Variation Totale',cmap = 'gray', width = 350, height = 350))\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoisingTVFB = DenoisingTVFB()\n",
    "pn.Row(denoisingTVFB.param, denoisingTVFB.view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style = 'color:blue'>\n",
    "\n",
    "### Commentaires:\n",
    "- Le paramètre `lambda` est très important, si il est grand, on rencontre l'effet de 'cartoon', et c'est difficile pour trouver le `lambda` optimal\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimisation la Variation Totale par FISTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FISTADenoisingTV(y, lamb, step, Niter, alpha = 3):\n",
    "    \n",
    "    p = np.array([np.zeros(y.shape), np.zeros(y.shape)])\n",
    "\n",
    "    grad = Gradient(- Div(p)) * (- Div(p) + y)\n",
    "    # grad[0] = np.dot(grad[0], - Div(p) + y)\n",
    "    # grad[1] = np.dot(grad[1], - Div(p) + y)\n",
    "    \n",
    "    p_old = p\n",
    "    p = ProjGradBouleInf(p - step * grad, lamb)\n",
    "    \n",
    "    for k in range(Niter):\n",
    "        temp = p + (k / (k + alpha)) * (p - p_old)\n",
    "        grad = Gradient(- Div(temp)) * (- Div(temp) + y)\n",
    "        # grad = np.dot(grad, - Div(p) + y)\n",
    "        # grad[0] = np.dot(grad[0], - Div(temp) + y)\n",
    "        # grad[1] = np.dot(grad[1], - Div(temp) + y)\n",
    "        p_old = p        \n",
    "        p = ProjGradBouleInf(temp - step * grad, lamb)\n",
    "    \n",
    "    x  = y + Div(p)\n",
    "    return np.clip(x, 0, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1, n2 = np.shape(lenna)\n",
    "Sigma = 30\n",
    "Noise = np.random.rand(n1, n2)\n",
    "lenna_noised = lenna + Sigma * Noise\n",
    "\n",
    "lenna_denoised_FISTA = FISTADenoisingTV(lenna_noised, lamb = 3.1, step = 0.1, Niter = 10000, alpha = 3)\n",
    "\n",
    "print(PSNR(lenna_noised, lenna))\n",
    "print(PSNR(lenna_denoised_FISTA, lenna))\n",
    "\n",
    "pn.Row(hv.Image(lenna).opts(title = 'Image originale', cmap='gray',width = 350, height = 350),\\\n",
    "       hv.Image(np.clip(lenna_noised, 0, 255)).opts(title = 'Image bruitée',cmap = 'gray',width = 350, height = 350)\\\n",
    "       ,hv.Image(lenna_denoised_FISTA).opts(title = 'Image débruitée par Variation Totale - FISTA',cmap = 'gray', width = 350, height = 350))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A retenir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si vous avez une descente de gradient ou un Forward-Backward à implémenter, les accélérations de Nesterov sont très souvent efficaces et il est toujours rentable de tester et même de tester différentes valeurs de $a$. Il est à noter toutefois que théoriquement sur des fonctions fortement convexes, pour l'algorithme FB, la suite de terme général $F(x_n)-F(x^*)$ décroit au moins géométriquement ce qui n'est pas le cas de l'accélération de Nesterov présentée ici qui sont au mieux polynomiales.\n",
    "Dans la pratique, pour un nombre raisonnable d'itérations, même dans ce cas, les accélérations de Nesterov sont largement compétitives.\n",
    "Mais il en existe d'autres encore plus efficaces spécifiquement dédiés à ce cas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
